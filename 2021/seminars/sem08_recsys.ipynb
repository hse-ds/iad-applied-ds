{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "colab": {
   "name": "sem08_recsys.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGvirHCNqQw2"
   },
   "source": [
    "## Прикладные задачи анализа данных 2021\n",
    "\n",
    "## Рекомендательные системы - 1\n",
    "\n",
    "Ссылка на этот ноутбук в колабе: \n",
    "https://colab.research.google.com/drive/1LeQZk5WbUoYrBqSDAyVMr7RyI_3c6ZAZ?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "By7Eu-JQqQw_"
   },
   "source": [
    "В этом задании будем практиковаться в реализации рекомендательных систем.\n",
    "\n",
    "Воспользуемся небольшим датасетом с Kaggle: [Articles Sharing and Reading from CI&T Deskdrop](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "719f3966-e6fd-49c8-9f60-7bd741542450",
    "_uuid": "b61cd3125a7f8f991fc1bda85ae3cd26f74090ae",
    "id": "85QpoXGIqQxA"
   },
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f5c826d-f3d5-42d3-a7e6-0343a44cdc9f",
    "_uuid": "26f1f70fd978957b26f8884fc5f82bfe9475c666",
    "id": "krOj16iWqQxB"
   },
   "source": [
    "## Часть 0. Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c48b62c-ad3b-4218-8fb2-2f0e86a16edc",
    "_uuid": "650c279eddc846a48274346e045cfb6e1f8895d5",
    "id": "LL6bq2kYqQxB"
   },
   "source": [
    "Загрузим Deskdrop dataset, включающийся в себе логи за 1 год платформы, где пользователи читают статьи.\n",
    "\n",
    "Данные включают в себя 2 файла:  \n",
    "- **shared_articles.csv**\n",
    "- **users_interactions.csv**\n",
    "\n",
    "Как можно догадаться, в одном описания самих статей (нам понадобятся в контентных моделях), а в другом логи пользователей."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ywrVWuT6qQxC"
   },
   "source": [
    "# загружаем и разархивируем данные\n",
    "!pip3 -q install cython\n",
    "!pip3 -q install git+https://github.com/coreylynch/pyFM\n",
    "!pip3 -q install catboost\n",
    "!wget -q -N https://www.dropbox.com/s/z8syrl5trawxs0n/articles.zip?dl=0 -O articles.zip\n",
    "!unzip -o -q articles.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9ee29ff-1fee-4dc9-a3cb-e5301c17fded",
    "_uuid": "1e66e976d34d4e28f5a92241b0ea82a2a66363ea",
    "id": "v2bKm5QJqQxC"
   },
   "source": [
    "#### shared_articles.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f09d2247-a40c-4aaf-90ce-15a8721a3036",
    "_uuid": "e64f4fa8a4751274bd2d37a0f45d2d3d664d6c3e",
    "id": "GxpMJN9SqQxC"
   },
   "source": [
    "Так как в файле перечислены даже удалённые статьи, то мы их сразу удалим (на самом деле они могли бы быть нам полезны для подсчёта различных величин, хоть мы и не можем их рекомендовать)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "e601f966-d03f-4edc-886f-ca3d511a8045",
    "_uuid": "569c301bd128f66f29b4d97c34171e4d1712015a",
    "id": "suDgBOcPqQxD"
   },
   "source": [
    "articles_df = pd.read_csv(\"shared_articles.csv\")\n",
    "articles_df = articles_df[articles_df[\"eventType\"] == \"CONTENT SHARED\"]\n",
    "articles_df.head(2)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "487936d5-d7b3-487d-9ef1-e3ba1e4bc421",
    "_uuid": "3f96f2d88fa86814e2fa1273d80f26d2559823fd",
    "id": "RJLNz-KhqQxE"
   },
   "source": [
    "#### users_interactions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "325b8db8-ef44-4b59-8138-2a59bd02d66e",
    "_uuid": "86694f1b80b04b8f9b961148fb265f355f202b26",
    "id": "PgJzS9gyqQxE"
   },
   "source": [
    "В колонке eventType описаны действия, которые могли совершать пользователи над статьёй:  \n",
    "- VIEW\n",
    "- LIKE\n",
    "- COMMENT CREATED\n",
    "- FOLLOW\n",
    "- BOOKMARK"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "445d39ec-f6b0-4155-9f92-0a2540918bd1",
    "_uuid": "9829842326037e364de457f832deceae074d6164",
    "id": "Owcr4wfBqQxF"
   },
   "source": [
    "interactions_df = pd.read_csv(\"users_interactions.csv\")\n",
    "interactions_df.head(10)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kt4kGdKIqQxF"
   },
   "source": [
    "interactions_df.personId = interactions_df.personId.astype(str)\n",
    "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
    "articles_df.contentId = articles_df.contentId.astype(str)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "585f81a5-c6ff-4399-bbec-901c41fc7285",
    "_uuid": "6abb0af8474eabb50be7a9e6496bfa75ec1b2bd9",
    "id": "3HB7GH94qQxF"
   },
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bad1a6c9-0258-4b89-85f9-bec89a523662",
    "_uuid": "84c2e91561d5de6afa7c45c173022193664c770e",
    "id": "X3I489s1qQxF"
   },
   "source": [
    "В логах встречаются различные действия пользователей. Однако мы хотим работать лишь с одной величиной, характеризующей всё взаимодействие пользователя со статьёй. Предлагается задать действиям следующие веса:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "3239c376-05b8-4a58-9afc-f6f57f67405f",
    "_uuid": "b06f8c0b082f0ad07bf773a5ad2fae33c1f7acc2",
    "id": "Futn6lM-qQxG"
   },
   "source": [
    "event_type_strength = {\n",
    "    \"VIEW\": 1.0,\n",
    "    \"LIKE\": 2.0,\n",
    "    \"BOOKMARK\": 2.5,\n",
    "    \"FOLLOW\": 3.0,\n",
    "    \"COMMENT CREATED\": 4.0,\n",
    "}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5FH1d6dqQxG"
   },
   "source": [
    "Посчитаем числовую величину \"оценки\" пользователем статьи с указанными выше весами."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aB8o-IYWqQxG"
   },
   "source": [
    "# interactions_df['eventStrength'] =\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################\n",
    "interactions_df[\"eventStrength\"]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c92aa80-2926-44db-b358-c4c32de806c4",
    "_uuid": "91100a395fdf4fb20df02c8d248072457c980b5d",
    "id": "Q1sUC2znqQxG"
   },
   "source": [
    "Ремендательные системы подвержены проблеме холодного старта. Будем работать только с теми пользователями, которые взаимодействовали хотя бы с 5-ю материалами.\n",
    "\n",
    "Оставим только таких пользователей."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "bad1d8ea-9b67-4a47-80c5-87a5e55c4f38",
    "_uuid": "1698c88340183baa7f3ebb8c3b60eaa8e6ca708f",
    "id": "btWf8QUPqQxH"
   },
   "source": [
    "users_interactions_count_df = (\n",
    "    interactions_df.groupby([\"personId\", \"contentId\"])\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .groupby(\"personId\")\n",
    "    .size()\n",
    ")\n",
    "print(\"# users:\", len(users_interactions_count_df))\n",
    "\n",
    "users_with_enough_interactions_df = users_interactions_count_df[\n",
    "    users_interactions_count_df >= 5\n",
    "].reset_index()[[\"personId\"]]\n",
    "print(\"# users with at least 5 interactions:\", len(users_with_enough_interactions_df))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ToYkE53lqQxH"
   },
   "source": [
    "users_interactions_count_df.hist(bins=5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myKXBFCIqQxH"
   },
   "source": [
    "Оставим только те взаимодействия, которые касаются только отфильтрованных пользователей."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "4e79a418-a9d6-4e01-9f38-9b290a645626",
    "_uuid": "0f428a4c6e76f95de7ea328dc33c6539389ae5f0",
    "id": "C2J-WTjwqQxH"
   },
   "source": [
    "# interactions_from_selected_users_df =\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RbRVx1E_qQxI"
   },
   "source": [
    "print(\"# interactions before:\", interactions_df.shape)\n",
    "print(\"# interactions after:\", interactions_from_selected_users_df.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6RKBJ_KqQxI"
   },
   "source": [
    "В данной постановке каждый пользователей мог взаимодействовать с каждой статьёй более 1 раза (как минимум совершая различные действия). Предлагается \"схлопнуть\" все действия в одно взаимодействие с весом, равным сумме весов. \n",
    "\n",
    "Однако полученное число будет в том числе тем больше, чем больше действий произвёл человек. Чтобы уменьшить разброс предлагается взять логарифм от полученного числа (можно придумывать другие веса действиям и по-другому обрабатывать значения).\n",
    "\n",
    "Также сохраним последнее значение времени взаимодействия для разделениея выборки на обучение и контроль."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "54c82dd1-1102-4f11-ac6a-7993f8e5e842",
    "_uuid": "dcd64b20b47cf2c365341303ff410626a801f7a6",
    "id": "xwDV_CKwqQxI"
   },
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1 + x, 2)\n",
    "\n",
    "\n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df.groupby([\"personId\", \"contentId\"])\n",
    "    .eventStrength.sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index()\n",
    "    .set_index([\"personId\", \"contentId\"])\n",
    ")\n",
    "interactions_full_df[\"last_timestamp\"] = interactions_from_selected_users_df.groupby(\n",
    "    [\"personId\", \"contentId\"]\n",
    ")[\"timestamp\"].last()\n",
    "\n",
    "interactions_full_df = interactions_full_df.reset_index()\n",
    "interactions_full_df.head(20)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17rTElxnqQxJ"
   },
   "source": [
    "Разобьём выборку на обучение и контроль по времени."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "e594a5ef-255a-4d30-9ab2-7cebe12fe798",
    "_uuid": "babda61be5306281b34422dbded67675a0aab17d",
    "id": "ZrK0kgemqQxJ"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_ts = 1475519530\n",
    "interactions_train_df = interactions_full_df.loc[\n",
    "    interactions_full_df.last_timestamp < split_ts\n",
    "].copy()\n",
    "interactions_test_df = interactions_full_df.loc[\n",
    "    interactions_full_df.last_timestamp >= split_ts\n",
    "].copy()\n",
    "\n",
    "print(\"# interactions on Train set: %d\" % len(interactions_train_df))\n",
    "print(\"# interactions on Test set: %d\" % len(interactions_test_df))\n",
    "\n",
    "interactions_train_df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOyOgs9WqQxJ"
   },
   "source": [
    "Также разбить данные можно не опираясь на временной фактор:\n",
    "```python\n",
    "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "                                   stratify=interactions_full_df['personId'], \n",
    "                                   test_size=0.25,\n",
    "                                   random_state=42)\n",
    "\n",
    "```\n",
    "Как повлият такое разбиение на итоговый результат?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjG6ezrJqQxJ"
   },
   "source": [
    "Для удобства подсчёта качества запишем данные в формате, где строка соответствует пользователю, а столбцы будут истинными метками и предсказаниями в виде списков."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vEHhflxYqQxJ"
   },
   "source": [
    "interactions = (\n",
    "    interactions_train_df.groupby(\"personId\")[\"contentId\"]\n",
    "    .agg(lambda x: list(x))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"contentId\": \"true_train\"})\n",
    "    .set_index(\"personId\")\n",
    ")\n",
    "\n",
    "interactions[\"true_test\"] = interactions_test_df.groupby(\"personId\")[\"contentId\"].agg(\n",
    "    lambda x: list(x)\n",
    ")\n",
    "\n",
    "# заполнение пропусков пустыми списками\n",
    "interactions.loc[pd.isnull(interactions.true_test), \"true_test\"] = [\n",
    "    list()\n",
    "    for x in range(\n",
    "        len(interactions.loc[pd.isnull(interactions.true_test), \"true_test\"])\n",
    "    )\n",
    "]\n",
    "\n",
    "interactions.head(1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2fac2a15-cc5c-4f31-8818-8065b0d2dc16",
    "_uuid": "59dd2131949c4d7e801114bffc11fb439c930b4c",
    "id": "S9gp8bM2qQxK"
   },
   "source": [
    "## Часть 1: Baseline (модель по популярности)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dHdmDp-qQxK"
   },
   "source": [
    "Самой простой моделью рекомендаций (при этом достаточно сильной!) является модель, которая рекомендует наиболее популярные предметы. \n",
    "\n",
    "Реализуем её. Давайте считать, что рекомендуем мы по 10 материалов (такое ограничение на размер блока на сайте).\n",
    "\n",
    "Посчитаем популярность каждой статьи, как сумму всех \"оценок\" взаимодействий с ней. Отсортируем материалы по их популярности."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4QJlz_JaqQxK"
   },
   "source": [
    "# popular_content =\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kxVmdoFvqQxL"
   },
   "source": [
    "print(articles_df.loc[articles_df.contentId == popular_content[2]][\"title\"].values)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hqGaYKbQqQxL"
   },
   "source": [
    "print(articles_df.loc[articles_df.contentId == popular_content[2363]][\"title\"].values)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D65fW3kGqQxL"
   },
   "source": [
    "Теперь необходимо сделать предсказания для каждого пользователя. Не забываем, что надо рекомендовать то, что пользователь ещё не читал (для этого нужно проверить, что материал не встречался в true_train)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nq5OeuGWqQxL"
   },
   "source": [
    "top_k = 10\n",
    "\n",
    "# interactions['prediction_popular'] =\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################\n",
    "interactions[\"prediction_popular\"][0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6VMmcGkqQxM"
   },
   "source": [
    "Настало время оценить качество. Посчитаем precision@10 для каждого пользователя (доля угаданных рекомендаций). Усредним по всем пользователям. Везде далее будем считать эту же метрику."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "11da-NKoqQxM"
   },
   "source": [
    "def calc_precision(column):\n",
    "    ####### Здесь ваш код ##########\n",
    "    raise NotImplementedError\n",
    "    ################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "48Epiu1sqQxM"
   },
   "source": [
    "calc_precision(\"prediction_popular\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7nlYgJwqQxM"
   },
   "source": [
    "## Часть 2. Коллаборативная фильтрация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DJGVppyqQxM"
   },
   "source": [
    "Перейдём к более сложному механизму рекомендаций, а именно коллаборативной фильтрации. Суть коллаборативной фильтрации в том, что учитывается схожесть пользователей и товаров между собой, а не факторы, которые их описывают. \n",
    "\n",
    "Для начала для удобства составим матрицу \"оценок\" пользователей. Нули будут обозначать отсутствие взаимодействия."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E29n5bpQqQxN"
   },
   "source": [
    "ratings = pd.pivot_table(\n",
    "    interactions_train_df, values=\"eventStrength\", index=\"personId\", columns=\"contentId\"\n",
    ").fillna(0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJQ3jqasqQxN"
   },
   "source": [
    "### Memory-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQGifAEiqQxN"
   },
   "source": [
    "Посчитаем схожести пользователей с помощью корреляции Пирсона. Для каждой пары учитываем только ненулевые значения.\n",
    "\n",
    "Для скорости работы лучше переходить от pandas к numpy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pt1p9MyaqQxN"
   },
   "source": [
    "ratings_m = ratings.values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j4FEpNbkqQxO"
   },
   "source": [
    "similarity_users = np.zeros((len(ratings_m), len(ratings_m)))\n",
    "\n",
    "for i in tqdm_notebook(range(len(ratings_m) - 1)):\n",
    "    for j in range(i + 1, len(ratings_m)):\n",
    "\n",
    "        # nonzero elements of two users\n",
    "        mask_uv = (ratings_m[i] != 0) & (ratings_m[j] != 0)\n",
    "\n",
    "        # continue if no intersection\n",
    "        if np.sum(mask_uv) == 0:\n",
    "            continue\n",
    "\n",
    "        # get nonzero elements\n",
    "        ratings_v = ratings_m[i, mask_uv]\n",
    "        ratings_u = ratings_m[j, mask_uv]\n",
    "\n",
    "        # for nonzero std\n",
    "        if len(np.unique(ratings_v)) < 2 or len(np.unique(ratings_u)) < 2:\n",
    "            continue\n",
    "        # similarity_users[i,j] =\n",
    "        # similarity_users[j,i] =\n",
    "        ####### Здесь ваш код ##########\n",
    "        raise NotImplementedError\n",
    "        ################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5hVpYHqqQxO"
   },
   "source": [
    "Теперь у нас есть матрицы схожести пользователей. Их можно использовать для рекомендаций.\n",
    "\n",
    "Для каждого пользователя:\n",
    "\n",
    "1. Найдём пользователей с похожестью больше $\\alpha$ на нашего пользователя.\n",
    "2. Посчитаем для каждой статьи долю пользователей (среди выделенных на первом шаге), которые взаимодействовали со статьёй.\n",
    "3. Порекомендуем статьи с наибольшими долями со второго шага (среди тех, которые пользователь ещё не видел).\n",
    "\n",
    "В нашем примере данных не очень много, поэтому возьмём $\\alpha = 0$.\n",
    "\n",
    "После того, как будут сделаны предсказания (новый столбец в interactions), посчитаем качество по той же метрике."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I3QQw7__qQxO"
   },
   "source": [
    "prediction_user_based = []\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################\n",
    "interactions[\"prediction_user_based\"] = prediction_user_based"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kfydUos3qQxO"
   },
   "source": [
    "calc_precision(\"prediction_user_based\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZyig2VtqQxO"
   },
   "source": [
    "### Модель со скрытыми переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRHrAO2MqQxP"
   },
   "source": [
    "Реализуем подход с разложением матрицы оценок. Для этого сделаем сингулярное разложение (svd в scipy.linalg), на выходе вы получите три матрицы.\n",
    "\n",
    "Заметим, что мы используем матрицу с нулями, будто отсутствующие взаимодействия негативные, что странно.\n",
    "\n",
    "Если бы мы учили модель со скрытыми переменными с помощью стохастического градиентного спуска, то неизвестные взаимодействия могли бы не использовать."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ml5CNWMcqQxP"
   },
   "source": [
    "from scipy.linalg import svd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fsHBlscWqQxP"
   },
   "source": [
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "biDdB7dBqQxP"
   },
   "source": [
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlPfBjSiqQxP"
   },
   "source": [
    "Значения у матрицы с сингулярными числами отсортированы по убыванию. Допустим мы хотим оставить только первые 100 компонент (и получить скрытые представления размерности 100). Для этого необходимо оставить 100 столбцов в матрице U, оставить из sigma только первые 100 значений (и сделать из них диагональную матрицу) и 100 столбцов в матрице V. Перемножим преобразованные матрицы ($\\hat{U}, \\hat{sigma}, \\hat{V^T}$), чтобы получить восстановленную матрицу оценок."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KriYvUs2qQxP"
   },
   "source": [
    "K = 100\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdNNtwUTqQxQ"
   },
   "source": [
    "Посчитаем качество аппроксимации матрицы по норме Фробениуса (среднеквадратичную ошибку между всеми элементами соответствующими элементами двух матриц). Сравним его с простым бейзлайном с константным значением, равным среднему значению исходной матрицы. У аппроксимации ошибка должна получиться ниже."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CL8w_5q-qQxQ"
   },
   "source": [
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ediwmw6aqQxQ"
   },
   "source": [
    "Теперь можно делать предсказания по матрице. Сделаем их (не забываем про то, что уже было просмотрено пользователем), оценим качество. Для этого необходимо для каждого пользователя найти предметы с наибольшими оценками в восстановленной матрице."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gd1gBXFnqQxQ"
   },
   "source": [
    "new_ratings = pd.DataFrame(new_ratings, index=ratings.index, columns=ratings.columns)\n",
    "\n",
    "predictions = []\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################\n",
    "interactions[\"prediction_svd\"] = predictions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "KT0YB-IfqQxQ"
   },
   "source": [
    "calc_precision(\"prediction_svd\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S6Fo-6eqQxQ"
   },
   "source": [
    "## Часть 3. Контентные  модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmOEsxYvqQxQ"
   },
   "source": [
    "В этой части реализуем альтернативный подход к рекомендательным системам — контентные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvejoC7lqQxR"
   },
   "source": [
    "Теперь мы будем оперировать не матрицей с оценками, а классической для машинного обучения матрицей объекты-признаки. Каждый объект будет характеризовать пару user-item и содержать признаки, описывающие как пользователя, так и товар. Кроме этого признаки могут описывать и саму пару целиком.\n",
    "\n",
    "Матрица со всеми взаимодействиями уже получена нами на этапа разбиения выборки на 2 части. \n",
    "\n",
    "Будем обучать классификатор на взаимодействие, а для него нужны отрицательные примеры. Добавим случайные отсутствующие взаимодействия как отрицательные.\n",
    "\n",
    "Заметим, что модель оценивает каждую пару потенциального взаимодействия, а значит, надо подготовить выборку из всех возможных пар из пользователей и статей."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6m19IyDpqQxR"
   },
   "source": [
    "test_personId = np.repeat(interactions.index, len(ratings.columns))\n",
    "test_contentId = list(ratings.columns) * len(interactions)\n",
    "test = pd.DataFrame(\n",
    "    np.array([test_personId, test_contentId]).T, columns=[\"personId\", \"contentId\"]\n",
    ")\n",
    "\n",
    "interactions_train_df = pd.concat(\n",
    "    (\n",
    "        interactions_train_df,\n",
    "        test.loc[np.random.permutation(test.index)[: 4 * len(interactions_train_df)]],\n",
    "    ),\n",
    "    ignore_index=True,\n",
    ")\n",
    "interactions_train_df.eventStrength.fillna(0, inplace=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNwTsDduqQxR"
   },
   "source": [
    "Придумаем и добавим признаков о пользователях и статьях. Сначала добавим информацию о статьях в данные о взаимодействиях."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F9j8uOZqqQxR"
   },
   "source": [
    "interactions_train_df = interactions_train_df.merge(\n",
    "    articles_df, how=\"left\", on=\"contentId\"\n",
    ")\n",
    "interactions_test_df = interactions_test_df.merge(\n",
    "    articles_df, how=\"left\", on=\"contentId\"\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tLdw-jVZqQxR"
   },
   "source": [
    "# first feature index\n",
    "features_start = len(interactions_train_df.columns)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5CnlZ3lqQxR"
   },
   "source": [
    "После обучения модели нам придётся делать предсказания на тестовой выборке для всех возможных пар статья-пользователь. Подготовим такую матрицу, чтобы параллельно посчитать признаки для неё."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GaGfk0xyqQxR"
   },
   "source": [
    "test_personId = np.repeat(interactions.index, len(articles_df))\n",
    "test_contentId = list(articles_df.contentId) * len(interactions)\n",
    "test = pd.DataFrame(\n",
    "    np.array([test_personId, test_contentId]).T, columns=[\"personId\", \"contentId\"]\n",
    ")\n",
    "test = test.merge(articles_df, how=\"left\", on=\"contentId\")\n",
    "\n",
    "test.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIteDguAqQxS"
   },
   "source": [
    "Добавим признаки-индикаторы возможных значений contentType."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0M_O53EjqQxS"
   },
   "source": [
    "interactions_train_df[\"is_HTML\"] = interactions_train_df.contentType == \"HTML\"\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThJ0YfEyqQxS"
   },
   "source": [
    "Добавим признаки \"длина названия\" и \"длина текста\" + некоторые проверки на ключевые слова."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uK6U_dq8qQxS"
   },
   "source": [
    "interactions_train_df[\"title_length\"] = interactions_train_df.title.fillna(\"\").apply(\n",
    "    len\n",
    ")\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7wBdEN-qQxS"
   },
   "source": [
    "Добавим признаки-индикаторы языка."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6gS4JN8dqQxS"
   },
   "source": [
    "interactions_train_df[\"is_lang_en\"] = interactions_train_df.lang == \"en\"\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxiHdbBdqQxS"
   },
   "source": [
    "Обучим на полученных признаках градиентный бустинг."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "922b4zXPqQxT"
   },
   "source": [
    "import catboost\n",
    "\n",
    "model = catboost.CatBoostClassifier()\n",
    "model.fit(\n",
    "    interactions_train_df[interactions_train_df.columns[features_start:]],\n",
    "    np.array(interactions_train_df.eventStrength > 0, dtype=int),\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUl6NXeBqQxT"
   },
   "source": [
    "Сделаем предсказания на тестовой выборке, сформируем из них рекомендации. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-R_VN9XEqQxT"
   },
   "source": [
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c482xq98qQxT"
   },
   "source": [
    "Оценим их качество."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "JALMeX5DqQxT"
   },
   "source": [
    "# calc_precision(...)\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sfoN8DXqQxT"
   },
   "source": [
    "## Часть 4. Факторизационная машина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TinQFAfqQxU"
   },
   "source": [
    "Вспомним, что факторизационная машина учитывает попарные взаимодействия признаков, что приводит сразу и к использованию контента (сами признаки), и к обучению скрытых представлений (индикаторы пользователей и статей).\n",
    "\n",
    "Попробуем факторизационные машины из библиотеки pyFM (так как можно работать прямо из питона). https://github.com/coreylynch/pyFM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B3ifB2McqQxU"
   },
   "source": [
    "from pyfm import pylibfm\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMbn4bsTqQxU"
   },
   "source": [
    "Перейдём к обобщению матричных разложений — факторизационным машинам, которые могут работать с контентной информацией. Вспомним, какие данные у нас изначально были:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLko8SExqQxU"
   },
   "source": [
    "В факторизационную машину можно загрузить \"айдишники\" пользователей и статей (то есть сделать аналог коллаборативной фильтрации) и одновременно различные признаки.\n",
    "\n",
    "Удобно обрабатывать категориальные переменные (id и другие) можно с помощью DictVectorizer. Например, процесс может выглядить вот так:\n",
    "```python\n",
    "train = [\n",
    "    {\"user\": \"1\", \"item\": \"5\", \"age\": 19},\n",
    "    {\"user\": \"2\", \"item\": \"43\", \"age\": 33},\n",
    "    {\"user\": \"3\", \"item\": \"20\", \"age\": 55},\n",
    "    {\"user\": \"4\", \"item\": \"10\", \"age\": 20},\n",
    "]\n",
    "v = DictVectorizer()\n",
    "X = v.fit_transform(train)\n",
    "y = np.repeat(1.0, X.shape[0])\n",
    "fm = pylibfm.FM()\n",
    "fm.fit(X,y)\n",
    "fm.predict(v.transform({\"user\": \"1\", \"item\": \"10\", \"age\": 24}))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQyuMPieqQxU"
   },
   "source": [
    "Сгенерируем таблицу с признаками в таком виде, где будут id пользователя, статьи и автора статьи и несколько признаков, которые вы сможете придумать."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y5SrdAvpqQxU"
   },
   "source": [
    "train_data = []\n",
    "\n",
    "for i in tqdm_notebook(range(len(interactions_train_df))):\n",
    "    features = {}\n",
    "    features[\"personId\"] = str(interactions_train_df.iloc[i].personId)\n",
    "    features[\"contentId\"] = str(interactions_train_df.iloc[i].contentId)\n",
    "    ####### Здесь ваш код ##########\n",
    "    raise NotImplementedError\n",
    "    ################################\n",
    "    train_data.append(features)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZcgOHfCqQxU"
   },
   "source": [
    "Повторим эту процедуру для тестовой выборки. Заметим, что модель оценивает каждую пару потенциального взаимодействия, а значит, надо подготовить выборку из всех возможных пар из пользователей и статей."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PHXjzLtlqQxV"
   },
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for i in tqdm_notebook(range(len(interactions))):\n",
    "    features = {}\n",
    "    features[\"personId\"] = str(interactions.index[i])\n",
    "    for j in range(len(ratings.columns)):\n",
    "        ####### Здесь ваш код ##########\n",
    "        raise NotImplementedError\n",
    "        ################################\n",
    "        test_data.append(deepcopy(features))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIQ3XWnpqQxV"
   },
   "source": [
    "Векторизуем, получим разреженные матрицы.\n",
    "\n",
    "Мы будем обучать регрессор на силу взаимодействия, а для него нужны отрицательные примеры. Добавим некоторое количество случайных примеров как негативные (матрица взаимодействий разреженная, поэтому шансы взять как негативное взаимодействие некоторое положительное мало)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "baRV9_xAqQxV"
   },
   "source": [
    "dv = DictVectorizer()\n",
    "\n",
    "train_features = dv.fit_transform(\n",
    "    train_data + list(np.random.permutation(test_data)[:100000])\n",
    ")\n",
    "test_features = dv.transform(test_data)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BAlJOSTRqQxV"
   },
   "source": [
    "train_features"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ur3qQ5HkqQxV"
   },
   "source": [
    "y_train = list(interactions_train_df.eventStrength.values) + list(np.zeros(100000))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Dp8jkPcqQxV"
   },
   "source": [
    "Укажем размером скрытого представления 10, сделаем 10 итераций."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "BippAnjNqQxV"
   },
   "source": [
    "# fm = pylibfm.FM(...\n",
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################\n",
    "fm.fit(train_features, y_train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xa-XBf5rqQxW"
   },
   "source": [
    "Предскажем и оценим качество."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8vHqEovcqQxW"
   },
   "source": [
    "####### Здесь ваш код ##########\n",
    "raise NotImplementedError\n",
    "################################"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mzW7hP86qQxW"
   },
   "source": [
    "predictions = []\n",
    "\n",
    "for i, person in enumerate(interactions.index):\n",
    "    user_prediction = ratings.columns[np.argsort(new_ratings[i])[::-1]]\n",
    "    predictions.append(\n",
    "        user_prediction[\n",
    "            ~np.in1d(user_prediction, interactions.loc[person, \"true_train\"])\n",
    "        ][:top_k]\n",
    "    )\n",
    "\n",
    "interactions[\"fm_prediction\"] = predictions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "REPS39o9qQxW"
   },
   "source": [
    "calc_precision(\"fm_prediction\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Js1IcKNcqQxW"
   },
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
